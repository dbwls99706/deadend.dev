{
  "schema_version": "1.0.0",
  "id": "cuda/tensor-device-mismatch/cuda12-linux",
  "url": "https://deadends.dev/cuda/tensor-device-mismatch/cuda12-linux",
  "error": {
    "signature": "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu",
    "regex": "Expected all tensors to be on the same device.*found at least two devices.*(cuda:\\d+ and cpu|cpu and cuda:\\d+)",
    "domain": "cuda",
    "category": "device_error",
    "first_seen": "2023-01-01",
    "last_confirmed": "2026-02-13"
  },
  "environment": {
    "runtime": {
      "name": "cuda",
      "version_range": ">=11.0,<13.0"
    },
    "os": "linux",
    "hardware": {
      "gpu": "NVIDIA",
      "vram_gb": 24
    }
  },
  "verdict": {
    "resolvable": "true",
    "fix_success_rate": 0.95,
    "confidence": 0.93,
    "last_updated": "2026-02-13",
    "summary": "Model parameters are on GPU but input tensors remain on CPU, or vice versa. Extremely common when .to(device) is not applied consistently to all tensors involved in an operation."
  },
  "dead_ends": [
    {
      "action": "Add .cuda() calls only to the model and not to the input data",
      "why_fails": "Both model parameters AND input tensors must be on the same device; moving only the model leaves input tensors on CPU",
      "fail_rate": 0.90,
      "sources": [
        "https://pytorch.org/docs/stable/notes/cuda.html#cuda-semantics"
      ],
      "condition": ""
    },
    {
      "action": "Wrap the entire forward pass in torch.no_grad() hoping to bypass the device check",
      "why_fails": "torch.no_grad() only disables gradient computation, it does not change tensor device placement or bypass device validation",
      "fail_rate": 0.95,
      "sources": [
        "https://pytorch.org/docs/stable/generated/torch.no_grad.html"
      ],
      "condition": ""
    },
    {
      "action": "Convert tensors to numpy and back to force device alignment",
      "why_fails": "Tensor.numpy() only works on CPU tensors and adds unnecessary overhead; the real fix is consistent .to(device) usage",
      "fail_rate": 0.85,
      "sources": [
        "https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html"
      ],
      "condition": ""
    }
  ],
  "workarounds": [
    {
      "action": "Define a single device variable and apply .to(device) to model, inputs, and labels consistently",
      "success_rate": 0.96,
      "how": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\ninputs = inputs.to(device)\nlabels = labels.to(device)",
      "sources": [
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ],
      "condition": ""
    },
    {
      "action": "Use a DataLoader with pin_memory=True and move batches to GPU inside the training loop",
      "success_rate": 0.92,
      "how": "loader = DataLoader(dataset, pin_memory=True)\nfor batch in loader:\n    inputs, labels = batch[0].to(device), batch[1].to(device)",
      "sources": [
        "https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
      ],
      "condition": ""
    },
    {
      "action": "Check intermediate tensors created inside the model (e.g., positional encodings, masks) are also on the correct device",
      "success_rate": 0.88,
      "how": "Inside nn.Module.forward(), use self.weight.device or input.device to create new tensors on the correct device: mask = torch.ones(size, device=input.device)",
      "sources": [
        "https://pytorch.org/docs/stable/notes/cuda.html#best-practices"
      ],
      "condition": "Model creates new tensors in forward() that default to CPU"
    }
  ],
  "transition_graph": {
    "leads_to": [
      {
        "error_id": "cuda/device-side-assert/cuda12-a100",
        "probability": 0.10,
        "condition": "After fixing device mismatch, shape or index bugs may surface as device-side asserts"
      }
    ],
    "preceded_by": [
      {
        "error_id": "cuda/torch-not-compiled-cuda/cuda12-rtx4090",
        "probability": 0.20,
        "condition": "After installing CUDA-enabled PyTorch, code that previously ran on CPU now partially moves to GPU"
      }
    ],
    "frequently_confused_with": [
      {
        "error_id": "python/cuda-out-of-memory/torch2.1-rtx3090",
        "distinction": "OOM errors occur when tensors are correctly on GPU but exceed VRAM; device mismatch means tensors are on different devices entirely"
      },
      {
        "error_id": "cuda/device-side-assert/cuda12-a100",
        "distinction": "Device-side assert is a kernel-level error from illegal operations; device mismatch is caught before any kernel launch"
      }
    ]
  },
  "metadata": {
    "generated_by": "bulk_generate.py",
    "generation_date": "2026-02-13",
    "review_status": "auto_generated",
    "evidence_count": 80,
    "last_verification": "2026-02-13"
  }
}
